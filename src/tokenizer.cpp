#include "tokenizer.h"
#include <iostream>

// Generated by flex.
int lexme(std::list<token> &);

void tokenizer::scan(){
    if(tokenlist.size() >= 1){
        lookahead.push_back( tokenlist.front() );
        tokenlist.pop_front();
    }
}

void tokenizer::prepare(){

    lexme(tokenlist);

    // Append an EOF token
    tokenlist.push_back(tkn_EOF);

    // Print list of tokens for debugging purposes.
    for(token &tkn : tokenlist){
        std::cout << tkn << " ";
    }
    std::cout << std::endl;
}

void tokenizer::syntaxerror(){
    // I have no idea when this gets called.
    std::cout << "syntaxerror?\n";
}
